{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure                       -0.342196\n",
      "Two year                     -0.302253\n",
      "One year                     -0.177820\n",
      "Dependents                   -0.164221\n",
      "Partner                      -0.150448\n",
      "NumServices                  -0.087698\n",
      "SeniorCitizen                 0.150889\n",
      "PaperlessBilling              0.191825\n",
      "MonthlyCharges                0.195872\n",
      "PayMethod_Electronic check    0.301919\n",
      "Month-to-month                0.405103\n",
      "Churn                         1.000000\n",
      "dtype: float64\n",
      "\n",
      "Binomial logistic regression model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1041\n",
      "           1       0.62      0.48      0.54       368\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.73      0.69      0.70      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n",
      "\n",
      "K Nearest Neighbors model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1041\n",
      "           1       0.59      0.49      0.53       368\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.71      0.68      0.69      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n",
      "\n",
      "Random forest model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1041\n",
      "           1       0.63      0.36      0.46       368\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.64      0.66      1409\n",
      "weighted avg       0.76      0.78      0.76      1409\n",
      "\n",
      "\n",
      "K nearest neighbors model with Gower distance:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      1041\n",
      "           1       0.55      0.43      0.48       368\n",
      "\n",
      "    accuracy                           0.76      1409\n",
      "   macro avg       0.68      0.65      0.66      1409\n",
      "weighted avg       0.74      0.76      0.75      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn\n",
    "from gower import gower_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "\n",
    "def encodeYesNo(df, cols: [str]):\n",
    "    df[cols] = df[cols].replace(to_replace=\"Yes\", value=1.0)\n",
    "    df[cols] = df[cols].replace(to_replace=\"No\", value=0.0)\n",
    "\n",
    "\n",
    "def encodeOneHot(df, col: str, prefix: str = None):\n",
    "    df = pd.concat([df, pd.get_dummies(df[col], dtype=float, prefix=prefix)], axis=1)\n",
    "    df = df.drop(col, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def groupByQuartile(df, col: str):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q2 = df[col].quantile(0.5)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    df[col] = df[col].apply(lambda x: 0 if x < q1 else 1 if x < q2 else 2 if x < q3 else 3)\n",
    "    return df\n",
    "\n",
    "def contractToYears(contract):\n",
    "    length = 0\n",
    "    if contract == \"One year\":\n",
    "        length = 1\n",
    "    elif contract == \"Two year\":\n",
    "        length = 2\n",
    "    return length\n",
    "\n",
    "class BinaryPredictor:\n",
    "    def __init__(self, df: pd.DataFrame, target: str, random_state=0, test_size=0.2):\n",
    "        self.data = df\n",
    "        self.target = target\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        df_train, df_test = train_test_split(df, random_state=random_state, test_size=test_size)\n",
    "        self.y_train = df_train[target].astype(int)\n",
    "        self.X_train = df_train.drop(target, axis=1)\n",
    "        self.y_test = df_test[target].astype(int)\n",
    "        self.X_test = df_test.drop(target, axis=1)\n",
    "\n",
    "    def fit_knn_gower(self, k=5):\n",
    "        gower_m = None\n",
    "        y = self.data[self.target].to_numpy()\n",
    "        X = self.data.drop(self.target, axis=1)\n",
    "        if (os.path.isfile('gower.csv')):\n",
    "            gower_m = np.loadtxt('gower.csv', delimiter=',').astype(float)\n",
    "        else:\n",
    "            gower_m = gower_matrix(X)\n",
    "            np.savetxt('gower.csv', gower_m, delimiter=',')\n",
    "\n",
    "        self.X_train_g, self.X_test_g, self.y_train_g, self.y_test_g = train_test_split(gower_m, y,\\\n",
    "            random_state=self.random_state, test_size=self.test_size)\n",
    "        self.knn_g = KNeighborsClassifier(n_neighbors=k).fit(self.X_train_g, self.y_train_g.astype(float))\n",
    "\n",
    "    def print_knn_gower_prediction(self):\n",
    "        y_pred = self.knn_g.predict(self.X_test_g)\n",
    "        print(\"\\nK nearest neighbors model with Gower distance:\\n\")\n",
    "        print(classification_report(self.y_test_g.astype(int), y_pred.astype(int)))\n",
    "\n",
    "    def fit_logistic_regression(self, solver='lbfgs'):\n",
    "        self.lrm = LogisticRegression(solver=solver).fit(self.X_train, self.y_train)\n",
    "  \n",
    "    def fit_knn(self, k=5):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=k).fit(self.X_train, self.y_train)\n",
    "\n",
    "    def fit_random_forest(self, max_depth=2, random_state=0):\n",
    "        self.rfc = RandomForestClassifier(max_depth=max_depth, random_state=random_state).fit(self.X_train, self.y_train)\n",
    "\n",
    "    def print_logistic_regression_prediction(self):\n",
    "        y_pred = self.lrm.predict(self.X_test)\n",
    "        print(\"\\nBinomial logistic regression model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "    \n",
    "    def print_knn_prediction(self):\n",
    "        y_pred = self.knn.predict(self.X_test)\n",
    "        print(\"\\nK Nearest Neighbors model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "    def print_random_forest_prediction(self):\n",
    "        y_pred = self.rfc.predict(self.X_test)\n",
    "        print(\"\\nRandom forest model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "#    def find_knn_neighbors(self, min=10, max=30):\n",
    "#        score = 0\n",
    "#        new_score = 0.001\n",
    "#        k = min\n",
    "#        while new_score > score:\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel('/home/arren/Downloads/WA_Fn-UseC_-Telco-Customer-Churn.xlsx')\n",
    "    df = df.dropna(axis=0)\n",
    "\n",
    "    #df['HighMonthlyLowTenure'] = df['MonthlyCharges']/df['tenure']\n",
    "    #df = groupByQuartile(df, 'HighMonthlyLowTenure')\n",
    "    encodeYesNo(df, ['Churn'])\n",
    "    df['tenure'] = df['tenure'].apply(lambda x: x//12)\n",
    "    #df['StabilityFactor'] = df['tenure'] + df['Contract'].apply(contractToYears)\n",
    "    #df = df.drop('tenure', axis=1) # we're including tenure in StabilityFactor aggregate features\n",
    "    #df = df.drop('Contract', axis=1) # \"\"\n",
    "\n",
    "    df = groupByQuartile(df, 'MonthlyCharges')\n",
    "\n",
    "    df = df.drop('customerID', axis=1) # customer ID isn't relevant for the model\n",
    "    df = df.drop('TotalCharges', axis=1) # Total charges is just monthly charge * tenure\n",
    "    df = df.drop('gender', axis=1) # on examining the correlations with Churn, male/female are insignificant (~0.0086)\n",
    "\n",
    "    df['MultipleLines'] = df['MultipleLines'].replace(to_replace=\"No phone service\", value=0.0)\n",
    "    encodeYesNo(df, ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'PaperlessBilling'])\n",
    "\n",
    "    df = encodeOneHot(df, 'InternetService', 'Internet')\n",
    "\n",
    "    internet_services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies'] \n",
    "    df[internet_services] = df[internet_services].replace(to_replace=\"No internet service\", value=0.0)\n",
    "    encodeYesNo(df, internet_services)\n",
    "\n",
    "    df['NumServices'] = df[internet_services].sum(axis=1)\n",
    "    df = df.drop(internet_services, axis=1)\n",
    "\n",
    "    df = encodeOneHot(df, 'Contract')\n",
    "\n",
    "    df = encodeOneHot(df, 'PaymentMethod', 'PayMethod')\n",
    "    #seaborn.relplot(data=df, y=\"tenure\", x=\"MonthlyCharges\", hue=\"Churn\")\n",
    "    #seaborn.barplot(data=corrs)\n",
    "    #seaborn.relplot(y=df['HighMonthlyLowTenure'], x=df.index, hue=df['Churn'])\n",
    "    #seaborn.pairplot(df)\n",
    "    df = df.drop('Internet_Fiber optic', axis=1) # this variable correlates strongly with churn, but it also correlates with high monthly charges\n",
    "    df = df.drop('Internet_No', axis=1) # this correlates strongly negatively with high monthly charges\n",
    "    #df = df.drop('MonthlyCharges', axis=1) # included in HighMonthlyLowTenure\n",
    "    low_corr_cols = ['PayMethod_Credit card (automatic)', 'Internet_DSL', 'PayMethod_Bank transfer (automatic)',\\\n",
    "        'PayMethod_Mailed check', 'PhoneService', 'MultipleLines'] # cols with less than .15 correlation with churn\n",
    "    df = df.drop(low_corr_cols, axis=1)\n",
    "\n",
    "\n",
    "    corrs = df.corrwith(df['Churn']).sort_values()\n",
    "    print(corrs)\n",
    "    #seaborn.heatmap(data=df.corr().abs())\n",
    "    bp = BinaryPredictor(df, target='Churn')\n",
    "    bp.fit_logistic_regression(solver='lbfgs')\n",
    "    bp.fit_knn(k=25)\n",
    "    bp.fit_random_forest(max_depth=4)\n",
    "    bp.print_logistic_regression_prediction()\n",
    "    bp.print_knn_prediction()\n",
    "    bp.print_random_forest_prediction()\n",
    "\n",
    "    #bp.fit_logistic_regression(solver='newton-cholesky')\n",
    "    #bp.print_logistic_regression_prediction()\n",
    "    bp.fit_knn_gower(k=25)\n",
    "    bp.print_knn_gower_prediction()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import seaborn\n",
    "from gower import gower_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class BinaryPredictor:\n",
    "    def __init__(self, df: pd.DataFrame, target: str, random_state=0, test_size=0.2):\n",
    "        self.data = df\n",
    "        self.target = target\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        df_train, df_test = train_test_split(df, random_state=random_state, test_size=test_size)\n",
    "        self.y_train = df_train[target].astype(int)\n",
    "        self.X_train = df_train.drop(target, axis=1)\n",
    "        self.y_test = df_test[target].astype(int)\n",
    "        self.X_test = df_test.drop(target, axis=1)\n",
    "\n",
    "    def fit_knn_gower(self, k=5):\n",
    "        gower_m = None\n",
    "        y = self.data[self.target].to_numpy()\n",
    "        X = self.data.drop(self.target, axis=1)\n",
    "        if (os.path.isfile('gower.csv')):\n",
    "            gower_m = np.loadtxt('gower.csv', delimiter=',').astype(float)\n",
    "        else:\n",
    "            gower_m = gower_matrix(X)\n",
    "            np.savetxt('gower.csv', gower_m, delimiter=',')\n",
    "\n",
    "        self.X_train_g, self.X_test_g, self.y_train_g, self.y_test_g = train_test_split(gower_m, y,\\\n",
    "            random_state=self.random_state, test_size=self.test_size)\n",
    "        self.knn_g = KNeighborsClassifier(n_neighbors=k).fit(self.X_train_g, self.y_train_g.astype(float))\n",
    "\n",
    "    def print_knn_gower_prediction(self):\n",
    "        y_pred = self.knn_g.predict(self.X_test_g)\n",
    "        print(\"\\nK nearest neighbors model with Gower distance:\\n\")\n",
    "        print(classification_report(self.y_test_g.astype(int), y_pred.astype(int)))\n",
    "\n",
    "    def fit_logistic_regression(self, solver='lbfgs'):\n",
    "        self.lrm = LogisticRegression(solver=solver).fit(self.X_train, self.y_train)\n",
    "  \n",
    "    def fit_knn(self, k=5):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=k).fit(self.X_train, self.y_train)\n",
    "\n",
    "    def fit_random_forest(self, max_depth=2, random_state=0):\n",
    "        self.rfc = RandomForestClassifier(max_depth=max_depth, random_state=random_state).fit(self.X_train, self.y_train)\n",
    "\n",
    "    def print_logistic_regression_prediction(self):\n",
    "        y_pred = self.lrm.predict(self.X_test)\n",
    "        print(\"\\nBinomial logistic regression model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "    \n",
    "    def print_knn_prediction(self):\n",
    "        y_pred = self.knn.predict(self.X_test)\n",
    "        print(\"\\nK Nearest Neighbors model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "    def print_random_forest_prediction(self):\n",
    "        y_pred = self.rfc.predict(self.X_test)\n",
    "        print(\"\\nRandom forest model:\\n\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "\n",
    "def main():\n",
    "    df = fetch_california_housing(as_frame=True)\n",
    "    print(type(df))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
